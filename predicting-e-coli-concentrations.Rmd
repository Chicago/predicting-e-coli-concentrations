---
title: Predicting E. coli concentrations using limited qPCR deployments at Chicago
  beaches
author: "Nick Lucius, many more and Tom Schenk Jr."
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    number_sections: yes
  pdf_document:
    number_sections: yes
  word_document: default
bibliography: zotero-references.bib
---

```{r setup_environment, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
## Install necessary packages

library(knitr)
library(knitcitations)

## Read bibliography
biblio <- read.bibtex("zotero-references.bib")
options("citation_format" = "pandoc")


```

> Culture-based methods to measure Escherichia coli (E. coli) are used by beach administrators to inform whether bacteria levels represent an elevated risk to swimmers. However, these methods take up to 12 hours for processing. Statistical models are used to forecast bacteria levels in lieu of test results. Often, these results underestimate days with elevated E. coli levels. In Chicago, these models only accurately predicted elevated levels 6.5% percent of the time in 2015.
> EPA approval of enterococci quantitative PCR (qPCR) methods allows for testing that is available within 3 hours, eschewing the need for predictive models. Unfortunately, these “rapid testing” methods are 100% to 400% more expensive than culture-based methods.
> This paper presents a prediction model which uses limited deployments of “rapid testing” sites with inter-beach correlation to predict when bacteria will exceed acceptable thresholds. The model can be used to inform management decisions on when to warn or close beaches due to exposure to the bacteria. Using data from Chicago, we find that the approach would have issued accurate advisories for 69 poor water quality “beach days” compared to 9 advisories issued by the previous model. The accuracy of the model rose from 4% to 12%--a 300% increase.


# Introduction

Managers of recreational beaches use culture-based methods to monitor bacteria levels at recreational beaches. Sampling is conducted early in the morning, but despite those effort, results take upward of 12 hours.  Between the time of sampling and subsequent results, beach conditions will often changes so the water sample is not relevant to todays beach conditions `r citep(biblio[c("whitman_interaction_1999","boehm_decadal_2002")])`. To get around this, researchers have developed statistical models--typically based on time-series projections--to estimate water quality conditions for the day. These models account for the past trend at the beaches and other factors such as precipitation, wind, and other related factors.

Yet, these models usually do not correctly identify days with elevated bacteria levels (known as Type II or "false negatives") `r citep(biblio["nevers_efficacy_2011"])`. In 2015, Chicago beaches had 200 events where bacteria levels were too high. However, only 13 (6.5%) of these events were forcasted by the predictive model. As we will discuss, these models do have good overall fit, but elevated bacteria levels are statistically rare events and models often fail to predict them.

Meanwhile, scientists have developed new methods which measure bacteria levels in water with substantially less delay. _Enterococci_ quantitative polymerase chain reaction (qPCR) methods can determine bacteria levels within a 3 to 4 hour time window an yield similar results as culture-based methods `r citep(biblio["haugland_comparison_2005"])`.

However, this approach has a drawback of cost and equipment availability. qPCR testing can cost between 2 to 5 times more than traditional culture-based methods `r ciptep(biblio["news_dna_nodate"])`. Thus, managers are faced with a dilemma of choosing between expensive qPCR methods or choosing slower culture-based methods and using predictive models to base swim advisories.

While culture-based and qPCR measure two completely different markers for bactereia, both of these tests have generally-acceptable thresholds for acceptable bacteria levels. Acceptable levels for culture-based methods should not exceed 235 MPN/100 ml while acceptable levels for qPCR testing should not exceed 1,000 cell equivalents (CE) `r citep(biblio["byappanahalli_linking_2010"])`. Within the context of beach management, these rules can be leveraged to create a new predictive model which mixed the short turn-around of qPCE method that can be applied to beaches without that more expensive equipment.

This paper proposed a hybrid model which uses readily available results from qPCR testing at select beaches to predict whether bacteria levels will be high at other beaches. We exploit the historical correlation between beaches to estimate water quality readings based solely on qPCR results that are available on the same day. As a result, these predictions can be used to "nowcast" water quality conditions.

This method eschews time-series based methods, which seem unreliable between summers and, as mentioned, fails to predict when bacteria levels are too high. This paper discusses attemps to formulate time-series models, but we conclude that time-series models often exhibit the same issues, likely because of the inability of statistical models to completely comphrehend the conditions which give rise to bacteria levels.

We find that the hybrid model is more accurate and consistent between seasons. Using data from 27 beaches managed by the Chicago Park District, we use 10 years of historical measurements to create a model to forecast whether bacteria levels at a beach will be elevated. During testing during the summer of 2017, the model was able to increase the accurate prediction of beaches by 200 percent. During the summer, the existing predictive model suggested that beaches will have elevated levels 9 times. The pilot model correctly suggested 60 additional beaches--for a total of 69 advisories. Meanwhile, the model did not increase the rate of falsly identifying days of high bacteria levels (known as Type I errors or "false positives").

Since water quality is not isolated to any one location. In additon to Chicago, there are XXXX beaches along the Great Lakes. Both because this paper proposes new methodology and that methodology can be useful for other locations, the data and underlying analytical model is available for all researchers, cities, and the public. We briefly discuss this approach and how it may be leveraged.  

# Background

Timing is a crucial factor for monitoring baacteria levels. We've adopted the typical shorthand to denote time periods by $t$ to denote now; $t-1$, $t-2$, $t-n$ to denote last period, two periods ago, and _some_ periods ago; and $t+1$, $t+2$, $t+n$ to denote the next period, two periods from now, and _some_ period in the future. For the purposes of this paper, we often use $t$ to denote _today_, $t-1$ to denote _yesterday_, and $t+1$ to denote _tomorrow_.

# Data

# Prior-day Model

The predominate forecasting technique uses prior bacteria testing results at beaches and other available data such as weather conditions, water conditions, or runoff.

These models rely on prior-day data since culture-based testing is not available until the next day. Expressing it as a linear regression model, the prediction at beach $x_i$ at time $t$ is dependent on the prior periods culture-based results, $x_i^{t-1}$ and other covariates, $w_1, w_2, ..., w_j$.

For a linear regression model, the coefficients $\beta_i$ provide the weight for how much each factor matters:

$$ x_i^t = f(x_i^{t-1}, w_1, w_2, ..., w_j) $$

Often $f(...)$ is a linear regression such that $x_i^t = \beta_1 x_i^{t-1} + \beta_2 w_1 + \beta_3 w_2 + ... + \beta_j w_j$. But, models sometimes use log transformations, genetic algorithms, or other methods. These class of models often have the same structure of using predictions from time $t-1$--the prior-day--and covariates from time $t$ to predict beaches at time $t$.

From 2006 to 2016, the Chicago Park District uses a model developed by the U.S. Geological Survey and Michigan State University to forecast whether bacteria levels will be elevated at Chicago beaches on Lake Michigan.

Recently, researchers have had an expanding toolkit of machine learning algorithms to formulate predictions. These algorithms can be swapped with $f(...)$ to forecast bacteria levels at beaches. In this section, we will propose various different "prior-day" models which use prior culture-based tests to predict whether bacteria levels exceed the acceptable threshold.

## Existing Methodology

## Ensemble Modeling



# Hybrid Model


Based on instability and inconsistency of the prior-day models, we infer that substantial information is lost between $t-1$ and $t$. It seems, though not conclusively, that information is lost between the two periods for a variety of reasons: incompleteness of the statistical predictors, failing to account for complex interaction terms in the statistical model, introduction of new factors between $t-1$ and $t$, etc.

Scientists have developed methods to reduce the reliance on data from $t-1$ to estimate levels at time $t$. One method to achieve this is qPCR methods which allow measurement at $t$ to render same-day information. However, this technique costs between 2 to 5 times more than traditional culture-based methods. With limited resources, it may not be feasible for recreational water managers to afford a deployment at all available locations.

Second, we propose that is possible to leverage qPCR measurements at select beaches to determine bacteria levels that did not have qPCR testing. `r \citet(biblio["whitman_summer_2008"])` noted that bacteria levels often flucuate which each other on the same day. Often, extreme highs and extreme lows were simultaneous for most beaches.

Hybrid modeling uses selected observations ($x_i^t$) from today $t$ using qPCR testing at some ($n$) beaches, that is $X^t: x_1^t, x_2^t, ..., x_n^t$, to forecast bacteria levels $y_i^t$ at other ($m$) beaches: $Y^t: y_1^t, y_2^t, ..., y_m^t$.

The key difference is using information at time $t$ to predict . Recall, prior-day models relied on using information for $t-1$ to predict levels at time $t$ because collection at $t$ is not avialable until later, $t+1$.

Hybrid models attempt to recast the research into a missing value problem. That is, from a research perspective, use information from the observed beaches to "fill-in" the data. Missing-value problems are common and often tackled in statistics in a variety of ways. For example, researchers can "fill-in" responses to surveys that were left partially blank. The general approach to missing-value problems is using observed correlations to fill-in missing values. 

In the context of beaches, we can leverage the historical, observed correlations between $x_i$ and $y_i$ and then leverage today's observations from qPCR testing, $x_i^t$ to "fill-in" beaches that do not have qPCR testing, $y_i^t$. Because it uses data from the same period, we suspect it is less susceptible to the problems that cause prior-day forecasting to be less reliable.


## Identifying Beach Clusters

We used clustering techniques to determine groups of beaches that tend to move in tandem. Specifically, identify beaches where bacteria levels and advisories are correlated with each other. We used K-means clustering algorithm to detect when beaches have similar movements. 

Given a number of desired clusters ($k$), the objective is to group a beach ($i$) with a cluster of other beaches ($B_k$) together that minimize the sum of squares. Mathematically:

$$ J(c_k) = \sum_{i=1}^{k} \sum_{x_i \in B_k} ||x_i - \mu_k||^2 $$

It is an algorithm which cannot be solved as a closed-form solution. Instead, the algorithm provides an initial guess for clusters and runs over multiple iterations to find the clusters which minimize the overall error. First, there is an initial, random guess for which beaches belong in clusters. The distance or error is then measured, $x_i - \mu_k$ for all clusters. Then, membership of clusters is slightly altered, the error is then measured and determined if the error is increasing or decreasing. This process is repeated until the lowest measured error is obtained.

We chose to limit to 5 clusters ($k = 5$) because it aligned to the number of qPCR testing sites by Chicago Parks District. K-means was applied to beaches based on latitude, longitude, total E. coli exceedances, and length of the longest breakwater. Each of these variables was scaled and centered by calculating z-scores prior to clustering. 

Some beaches were removed from the clustering because they were historical outliers for bacteria levels or had distinct physical features. Namely, we removed beaches that have lengthy breakwaters which have an impact on bacteria levels at those beaches (). We tested this hypothesis by measuring the distance of the southernmost part of the beach to the northeasternmost edge of the breakwater. The correlation between the breakwater and bacteria exceedances between 2006 and 2017 were positive (R^2 = 0.54). We removed beaches (which ones?) that have long breakwaters. Likewise, our earlier analytical modeling showed that beaches with a high frequency of high bacteria levels often confounded the model. These beaches (which ones) were also removed from the analytical model.


The remaining four clusters were reanalyzed using 5-cluster k-means with the same variables. 

| Cluster 1 |   Cluster 2  | Cluster 3 | Cluster 4 |  Cluster 5  |
|-----------|--------------|-----------|-----------|-------------|
|  Foster   | North Avenue |   Leone   |    31st   | South Shore |
| Osterman  | Oak Street   |  Juneway  |    12th   |     57th    |
|  Albion   |              |   Howard  |    39th   |             |
|           |              |   Rogers  |           |             |
|           |              |   Jarvis  |           |             |


Within each cluster, the beach with the most E. coli exceedances was selected for use as a model feature. The remaining beaches were selected to be predicted by the model.

| Feature Beaches | Predicted Beaches |
|-----------------|-------------------|
|   South Shore   |       57th        |
|      31st       |       39th        |
|   North Avenue  |       12th        |
|     Foster      |     Oak Street    |
|     Leone       |     Osterman      |
|                 |      Albion       |
|                 |      Juneway      |
|                 |       Howard      |
|                 |       Rogers      |
|                 |       Jarvis      |

## Building the Predictive Model

A random forest regression model was trained with the following features: the predicted beach's name and culture-based results for each of the feature beaches. The model was fit to predict the culture-based result for the predicted beach on the same day. The model was tuned and validated using leave-one-year-out cross validation, in which the validation set consisted of all the observations in one year, and the training set consisted of all other observations. The process was repeated until each year had been in the validation set. The year 2016 was left out as a final validation set.

Historically, the USGS model from 2006 through 2016 had a false-positive rate of 1.8 percent. That is, the USGS model falsely predicted elevated bacteria levels 1.8 percent of all beach days over the course of the summer--typically 30 beach-days per season. We chose to align the parameters of our model to the historical false-positive rate. As Figure 2 shows, we could increase the number of times we correctly predict elevated bacteria levels, but it comes at a cost of also increasing the number of days were we falsely provide warnings to beach-goers.

Figure XX shows the receiver operating characteristic (ROC), which shows the trade-off between increasing the number of days with true predictions versus days we falsely identify elevated levels. By constraining our model to only have a 1.8 percent false-positive rate, our true positive rate is forecasted to be 22 percent.

(FIGURE XX)

A threshold was chosen to transform the model prediction to a binary outcome. To keep the model's false positive rate (FPR) near 1.5%, the threshold within each year that corresponded to a 1.5% FPR was noted, and the mean threshold was then used to generate predictions for the holdout validation set. 

In summer 2017, the model concept was piloted with some limitations imposed by available data. The feature beaches were Calumet, Rainbow, South Shore, 63rd, and Montrose, and the predicted beaches were the other 15 regularly tested beaches. The model was trained using qPCR test results for 2015 and 2016 and fit to predict the culture-based levels for the predicted beach on the same day. An application was developed and deployed which regularly checked Chicago's public data portal for qPCR results for the feature beaches. Every day during the summer, once all the qPCR results were posted, the application automatically ran the model and uploaded the predictions on the public data portal within five minutes. 

## Validating the Algorithm - Summer 2017

The analytical model was created using historical data from 2015 and 2016. However, to correctly assess the accuracy of the model, we need to use out-of-sample predictions. Within machine learning, it is possible that the accuracy of the model was caused by the analysts tuning the model to existing data and then fail to predict when data has not already been accounted for.

Using the training data through 2016, we used the summer of 2017 to predict elevated levels and then measure the accuracy at the end of the season. This provided the same scenario as beach forecasting models: read the most recent data, formulate a prediction, collect water samples, and then compare the predictions to the collected samples. 

qPCR measurements from 5 beaches: Calumet, Rainbow, Sourth Share, 63rd, and Montrose, were used to predict the qPCR levels at the other 15 regularly tested beaches. Beginning on Friday, May 26, we posted the predictions based on our model to the City of Chicago Data Portal at 6am. Water samples were then collected by the Chicago Park District and tested by the University of Illinois at Chicago. Those results were then posted to the City of Chicago Data Portal when they were available--typically around noon. The last predictions and samples were conducted on September 4th. 

Both predictions and samples were collected each day during the week. This process was different from prior years where samples were usually collected only during weekdays and non-holidays except when levels had been elevated on the previous Friday or was suspected to be a busy weekend on the beaches.

In summer 2017, the model concept was piloted with some limitations imposed by available data... (let's specify this)

Table XX shows the truth table for the results of the pilot. Each quadrant shows the relationship between the prediction (whether the model provided an advisory) versus the actual results from qPCR testing (whether there were levels above XXXX amount). 

Over the summer, the analytical model had a true positive rate of 11.2 percent compared to a true positive rate of 3.2 percent in 2016. Over the past decade, the historical average true positive rate for those beaches was 3.3 percent. That is, the hybrid model increased the true positive rate by 239 percent over the historical average.

Meanwhile, the false positive rate was slightly higher at 2.0 percent during 2017. Our target rate was 1.5 percent to remain consistent with prior summers. Though higher than desired, the previous model had a false rate of 2 percent or higher (how many times out of the past 10 years??).

(HISTORICAL GRAPH OF ACTUAL TPR/FPR LEVELS FOR USGS AND HYBRID MODEL)

In terms of impact on beachgoers, the hybrid model issued 90 correct advisories while there were 71 incorrect advisories. While we cannot directly compare it to the USGS model, in 2016 that model issued 12 correct advisories while issuing 184 incorrect advisories. Likewise in 2015, there were 14 correct advisories versus 184 incorrect advisories.

Nevertheless, the hybrid model still failed to identify days with elevated levels; the false negative rate. (How many??)



# Open Science

# Summary

# References


```{r references, echo=FALSE, message=FALSE}
write.bibtex(file="bibliography.bib")
```
